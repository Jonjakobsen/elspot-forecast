{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a7b2f8",
   "metadata": {},
   "source": [
    "# 02 – Model Training  \n",
    "Denne notebook træner en GRU-model til forudsigelse af day-ahead spotpriser baseret på vejr- og tidsdata.  \n",
    "Der udføres grid search over udvalgte hyperparametre, og den bedste model gemmes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36af75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sikr at mappen findes, ellers opret\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Indlæs data\n",
    "df = pd.read_csv(\"../data/processed/merged.csv\", parse_dates=[\"TimeDK\"])\n",
    "\n",
    "\n",
    "TIME_COL = \"TimeDK\"\n",
    "PRICE_COL = \"SpotPriceDKK\"\n",
    "FEATURES = [\"Temperature\", \"WindSpeed\", \"SolarRadiation\"]\n",
    "df = df.sort_values(TIME_COL).reset_index(drop=True)\n",
    "\n",
    "# Feature engineering\n",
    "df[\"hour\"] = df[TIME_COL].dt.hour\n",
    "df[\"dow\"] = df[TIME_COL].dt.dayofweek\n",
    "FEATURES = FEATURES + [\"hour\", \"dow\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cee689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scaling ---\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X = scaler_X.fit_transform(df[FEATURES])\n",
    "y = scaler_y.fit_transform(df[[PRICE_COL]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SEQ_LEN = 24\n",
    "X_seq, y_seq = [], []\n",
    "for i in range(0, len(df) - SEQ_LEN + 1, SEQ_LEN):\n",
    "    X_seq.append(X[i:i+SEQ_LEN])        # 24 timers vejrinput\n",
    "    y_seq.append(y[i:i+SEQ_LEN])        # 24 timers priser for samme vindue\n",
    "X_seq, y_seq = np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "fejl_fundet = False\n",
    "\n",
    "for i, seq in enumerate(X_seq):\n",
    "    # Inversér kun den enkelte sekvens\n",
    "    seq_inv = scaler_X.inverse_transform(seq)\n",
    "    hours = seq_inv[:, 3]  # kolonne 3 = time\n",
    "    if not np.array_equal(hours, np.arange(24)):\n",
    "        print(f\"Fejl i sekvens {i}: {hours}\")\n",
    "        fejl_fundet = True\n",
    "\n",
    "if not fejl_fundet:\n",
    "    print(\"ingen fejl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4958d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Split (kronologisk 80/20) ---\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb60ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"Running on:\", device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb394b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gem scalers\n",
    "joblib.dump(scaler_X, \"../models/scaler_X.gz\")\n",
    "joblib.dump(scaler_y, \"../models/scaler_y.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model ---\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=None, num_layers=None, dropout=None):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)  # ét output per time\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8475be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Træningsfunktion ---\n",
    "def train_and_validate(model, train_dl, test_dl, optimizer, criterion, model_path, epochs=1000, patience=5):\n",
    "    best_val = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        batch_losses = []\n",
    "\n",
    "        for xb, yb in train_dl:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "        train_mse = sum(batch_losses) / len(batch_losses)\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_batch_losses = []\n",
    "            for xb, yb in test_dl:\n",
    "                pred = model(xb)\n",
    "                val_loss = criterion(pred, yb)\n",
    "                val_batch_losses.append(val_loss.item())\n",
    "        val_mse = sum(val_batch_losses) / len(val_batch_losses)\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "\n",
    "          print(f\"Epoch {epoch+1}/{epochs}   Val MSE: {val_mse:.5f}     Train MSE: {train_mse:.5f}\")\n",
    "\n",
    "        # --- Early stopping ---\n",
    "        if val_mse < best_val:\n",
    "            best_val = val_mse\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    return best_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93659ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Grid search setup ---\n",
    "param_grid = {\n",
    "    \"hidden_size\": [16, 32, 64],\n",
    "    \"num_layers\": [1, 2],\n",
    "    \"dropout\": [0.0, 0.2, 0.5],\n",
    "    \"lr\": [1e-3, 1e-4],\n",
    "    \"batch_size\": [32, 64],\n",
    "}\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "results = []\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "best_model_state = None\n",
    "best_params = None\n",
    "\n",
    "for hidden, layers, dropout, lr, batch in itertools.product(\n",
    "    param_grid[\"hidden_size\"],\n",
    "    param_grid[\"num_layers\"],\n",
    "    param_grid[\"dropout\"],\n",
    "    param_grid[\"lr\"],\n",
    "    param_grid[\"batch_size\"]):\n",
    "\n",
    "    print(f\"\\n=== Træner model: hidden={hidden}, layers={layers}, dropout={dropout}, lr={lr}, batch={batch} ===\")\n",
    "\n",
    "    train_ds = TensorDataset(X_train, y_train)\n",
    "    test_ds = TensorDataset(X_test, y_test)\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch, shuffle=False)\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch, shuffle=False)\n",
    "\n",
    "    model = GRUModel(X_train.shape[2], hidden, layers, dropout).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    val_loss = train_and_validate(model, train_dl, test_dl, optimizer, criterion, model_path=\"tmp.pt\")\n",
    "\n",
    "    results.append({\n",
    "        \"hidden_size\": hidden,\n",
    "        \"num_layers\": layers,\n",
    "        \"dropout\": dropout,\n",
    "        \"lr\": lr,\n",
    "        \"batch_size\": batch,\n",
    "        \"val_loss\": val_loss,\n",
    "    })\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        best_params = {\n",
    "            \"hidden_size\": hidden,\n",
    "            \"num_layers\": layers,\n",
    "            \"dropout\": dropout,\n",
    "            \"lr\": lr,\n",
    "            \"batch_size\": batch,\n",
    "        }\n",
    "        best_model_state = model.state_dict().copy()\n",
    "\n",
    "# --- Gem kun bedste model ---\n",
    "best_path = os.path.join(\"../models\", \"best_model.pt\")\n",
    "torch.save(best_model_state, best_path)\n",
    "\n",
    "# Gem hyperparametre\n",
    "with open(os.path.join(\"../models\", \"best_params.json\"), \"w\") as f:\n",
    "    json.dump(best_params, f)\n",
    "\n",
    "print(\"\\nBedste model gemt:\")\n",
    "print(best_params)\n",
    "print(f\"Valideringstab: {best_val:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b457b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test modellen\n",
    "\n",
    "with open(\"../models/best_params.json\", \"r\") as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "best_model = GRUModel(\n",
    "    input_size=X_train.shape[2],\n",
    "    hidden_size=best_params[\"hidden_size\"],\n",
    "    num_layers=best_params[\"num_layers\"],\n",
    "    dropout=best_params[\"dropout\"]\n",
    ").to(device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(\"../models/best_model.pt\", map_location=device))\n",
    "best_model.eval()\n",
    "\n",
    "# --- Forudsigelser ---\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = best_model(X_test).cpu().numpy()\n",
    "    y_true = y_test.cpu().numpy()\n",
    "\n",
    "\n",
    "# --- Rescaler hvis du brugte scaler ---\n",
    "y_pred_real = scaler_y.inverse_transform(y_pred.reshape(-1, 1)).reshape(y_pred.shape)\n",
    "y_true_real = scaler_y.inverse_transform(y_true.reshape(-1, 1)).reshape(y_true.shape)\n",
    "\n",
    "# Plot nogle eksempler\n",
    "for d in [1,5,50,100]:\n",
    "\n",
    "\n",
    "\n",
    "  plt.figure(figsize=(8,4))\n",
    "  plt.plot(y_true_real[d,:,0], label=\"Faktisk pris\")\n",
    "  plt.plot(y_pred_real[d,:,0], label=\"Prediktion\")\n",
    "  plt.title(f\"Elpris – døgn {d}\")\n",
    "  plt.xlabel(\"Time på dagen\")\n",
    "  plt.ylabel(\"Spotpris [DKK/MWh]\")\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
